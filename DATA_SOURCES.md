#Potential Data Sources:

##BP4D
http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html

###Contents
2D and 3D FACS coding from spontaneous video
41 participants (23 women, 18 men)
They were 18 – 29 years of age; 11 were Asian, 6 were African-American, 4 were Hispanic, and 20 were Euro-American 

###Access
Lengthy request process from binghamton
must cite: 
BP4D-Spontaneous: A high resolution spontaneous 3D dynamic facial expression database (2014)
& A high resolution spontaneous 3D dynamic facial expression database (2013)

##RU-FACS - UCSD
http://mplab.ucsd.edu/grants/project1/research/rufacs1-dataset.html

###Contents
100 subjects, 2.5 min each
Spontaneous expressions

###Access
Can't find a place to download, the only info is from 2004. Might need to email for access

##Cohn–Kanade - Pitt (requested)
http://www.pitt.edu/~emotion/ck-spread.htm

###Contents
Initial release: 97 subjects, 468 sequences (posed)
Second release: Addition of spontaneously coded sequences, increase in number of subjects and sequences
Third release: Frontal + 30 degree turn from camera views synced

###Access
Fill out form and download from this site: http://www.consortium.ri.cmu.edu/ckagree/

##DISFA - Denver (need chang to fill out)

###Contents
27 adults (12 women and 15 men)
Manually annotated 12 AUs
Spontaneous source video, 130,000 frames

###Access
Available for download at: http://mohammadmahoor.com/databases/denver-intensity-of-spontaneous-facial-action/

##MMI (requested)
http://mmifacedb.eu/
###Contents
75 subjects
2900 videos
All posed, variable lighting
Coded AUs

###Access
Download by making an account here: http://mmifacedb.eu/collections/

##AM-FED - MIT/Affectiva (requested)
http://www.affectiva.com/facial-expression-dataset/

###Contents
(from the website)
This dataset consists of 242 facial videos (168,359 frames) recorded in real world conditions. The database is comprehensively labeled for the following:

1. Frame- by-frame labels for the presence of: a) 10 symmetrical FACS action units; b) 4 asymmetric (unilateral) FACS action units; c) 2 head movements, smile, general expressiveness, feature tracker fails; d) Gender.

2. The location of 22 automatically detected landmark points.

3. Self-report responses of familiarity with, liking of, and desire to watch again for the stimuli videos.

4. Baseline performance of detection algorithms on this dataset. We provide baseline results for smile and AU2 (outer eyebrow raise) on this dataset using custom AU detection algorithms.

###Access
Send EULA to amfed@affectiva.com, will get download instructions in email